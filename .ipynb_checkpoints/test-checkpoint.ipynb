{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# !pip uninstall pandas\n",
    "# !pip install pandas==0.20.2\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../test/data.py\")\n",
    "from data import load_data\n",
    "import pandas as pd\n",
    "print(pd.__version__)\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.utils import np_utils\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "# import seaborn as sn\n",
    "# from sklearn.utils import shuffle\n",
    "# from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loding datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Training data\n",
    "# body_acc_x_train = pd.read_table(\"./body_acc_x_train.txt\", delim_whitespace=True,header=None)\n",
    "# body_acc_y_train = pd.read_table(\"./body_acc_y_train.txt\", delim_whitespace=True,header=None)\n",
    "# body_acc_z_train = pd.read_table(\"./body_acc_z_train.txt\", delim_whitespace=True,header=None)\n",
    "# body_gyro_x_train = pd.read_table(\"./body_gyro_x_train.txt\", delim_whitespace=True,header=None)\n",
    "# body_gyro_y_train = pd.read_table(\"./body_gyro_y_train.txt\", delim_whitespace=True,header=None)\n",
    "# body_gyro_z_train = pd.read_table(\"./body_gyro_z_train.txt\", delim_whitespace=True,header=None)\n",
    "# total_acc_x_train = pd.read_table(\"./total_acc_x_train.txt\", delim_whitespace=True,header=None)\n",
    "# total_acc_y_train = pd.read_table(\"./total_acc_y_train.txt\", delim_whitespace=True,header=None)\n",
    "# total_acc_z_train = pd.read_table(\"./total_acc_z_train.txt\", delim_whitespace=True,header=None)\n",
    "\n",
    "# label_train = pd.read_table(\"./y_train.txt\", delim_whitespace=True,header=None)\n",
    "\n",
    "# #Testing data\n",
    "# body_acc_x_test = pd.read_table(\"./body_acc_x_train.txt\", delim_whitespace=True,header=None)\n",
    "# body_acc_y_test = pd.read_table(\"./body_acc_y_train.txt\", delim_whitespace=True,header=None)\n",
    "# body_acc_z_test = pd.read_table(\"./body_acc_z_train.txt\", delim_whitespace=True,header=None)\n",
    "# body_gyro_x_test = pd.read_table(\"./body_gyro_x_train.txt\", delim_whitespace=True,header=None)\n",
    "# body_gyro_y_test = pd.read_table(\"./body_gyro_y_train.txt\", delim_whitespace=True,header=None)\n",
    "# body_gyro_z_test = pd.read_table(\"./body_gyro_z_train.txt\", delim_whitespace=True,header=None)\n",
    "# total_acc_x_test = pd.read_table(\"./total_acc_x_train.txt\", delim_whitespace=True,header=None)\n",
    "# total_acc_y_test = pd.read_table(\"./total_acc_y_train.txt\", delim_whitespace=True,header=None)\n",
    "# total_acc_z_test = pd.read_table(\"./total_acc_z_train.txt\", delim_whitespace=True,header=None)\n",
    "\n",
    "# label_test = pd.read_table(\"./y_test.txt\", delim_whitespace=True,header=None)\n",
    "\n",
    "# dickey = {\"1\":\"WALKING\", \"2\":\"WALKING_UPSTAIRS\",\"3\":\"WALKING_DOWNSTAIRS\",\"4\":\"SITTING\",\"5\":\"STANDING\",\"6\":\"LAYING\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# body_acc_x_train_3d = tf.expand_dims(body_acc_x_train, 2)\n",
    "# body_acc_y_train_3d = tf.expand_dims(body_acc_y_train, 2)\n",
    "# body_acc_z_train_3d = tf.expand_dims(body_acc_z_train, 2)\n",
    "# body_gyro_x_train_3d = tf.expand_dims(body_gyro_x_train, 2)\n",
    "# body_gyro_y_train_3d = tf.expand_dims(body_gyro_y_train, 2)\n",
    "# body_gyro_z_train_3d = tf.expand_dims(body_gyro_z_train, 2)\n",
    "# total_acc_x_train_3d = tf.expand_dims(total_acc_x_train, 2)\n",
    "# total_acc_y_train_3d = tf.expand_dims(total_acc_y_train, 2)\n",
    "# total_acc_z_train_3d = tf.expand_dims(total_acc_z_train, 2)\n",
    "\n",
    "\n",
    "# result = tf.concat([body_acc_x_train_3d, body_acc_y_train_3d, body_acc_z_train_3d,\n",
    "#                     body_gyro_x_train_3d, body_gyro_y_train_3d, body_gyro_z_train_3d,\n",
    "#                     total_acc_x_train_3d, total_acc_y_train_3d, total_acc_z_train_3d,\n",
    "#                     body_acc_x_train_3d, body_acc_y_train_3d, body_acc_z_train_3d], 2)\n",
    "# result = tf.expand_dims(result,3)\n",
    "# print(result.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshaping datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Training data\n",
    "# temp = np.array([body_acc_x_train.to_numpy().T,\n",
    "#                  body_acc_y_train.to_numpy().T,\n",
    "#                  body_acc_z_train.to_numpy().T,\n",
    "#                  body_gyro_x_train.to_numpy().T,\n",
    "#                  body_gyro_y_train.to_numpy().T,\n",
    "#                  body_gyro_z_train.to_numpy().T,\n",
    "#                  total_acc_x_train.to_numpy().T,\n",
    "#                  total_acc_y_train.to_numpy().T,\n",
    "#                  total_acc_z_train.to_numpy().T,\n",
    "#                  body_acc_x_train.to_numpy().T,\n",
    "#                  body_acc_y_train.to_numpy().T,\n",
    "#                  body_acc_z_train.to_numpy().T]).T\n",
    "# X_train = temp.reshape(temp.shape[0],temp.shape[1],temp.shape[2],1)\n",
    "\n",
    "# y_train = keras.utils.to_categorical(label_train.to_numpy())\n",
    "# y_train = np.delete(y_train,0,1)\n",
    "\n",
    "# print(X_train.shape)\n",
    "# #Testing data\n",
    "# temp = np.array([body_acc_x_test.to_numpy().T,\n",
    "#                  body_acc_y_test.to_numpy().T,\n",
    "#                  body_acc_z_test.to_numpy().T,\n",
    "#                  body_gyro_x_test.to_numpy().T,\n",
    "#                  body_gyro_y_test.to_numpy().T,\n",
    "#                  body_gyro_z_test.to_numpy().T,\n",
    "#                  total_acc_x_test.to_numpy().T,\n",
    "#                  total_acc_y_test.to_numpy().T,\n",
    "#                  total_acc_z_test.to_numpy().T,\n",
    "#                  body_acc_x_test.to_numpy().T,\n",
    "#                  body_acc_y_test.to_numpy().T,\n",
    "#                  body_acc_z_test.to_numpy().T]).T\n",
    "# X_test = temp.reshape(temp.shape[0],temp.shape[1],temp.shape[2],1)\n",
    "# y_test = keras.utils.to_categorical(label_test.to_numpy())\n",
    "# y_test = np.delete(y_test,0,1)\n",
    "# print(body_acc_x_train[2][10])\n",
    "# print(X_train[0][2][10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.array([body_acc_x_train.to_numpy().T,\n",
    "#                  body_acc_y_train.to_numpy().T,\n",
    "#                  body_acc_z_train.to_numpy().T,\n",
    "#                  body_gyro_x_train.to_numpy().T,\n",
    "#                  body_gyro_y_train.to_numpy().T,\n",
    "#                  body_gyro_z_train.to_numpy().T,\n",
    "#                  total_acc_x_train.to_numpy().T,\n",
    "#                  total_acc_y_train.to_numpy().T,\n",
    "#                  total_acc_z_train.to_numpy().T,\n",
    "#                  body_acc_x_train.to_numpy().T,\n",
    "#                  body_acc_y_train.to_numpy().T,\n",
    "#                  body_acc_z_train.to_numpy().T].T.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2947, 128, 12)\n",
      "(7352, 128, 12)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = load_data()\n",
    "# X_train = X_train.reshape(X_train.shape[0],X_train.shape[1],X_train.shape[2],1)\n",
    "print(X_test.shape)\n",
    "# X_test = X_test.reshape(X_test.shape[0],X_test.shape[1],X_test.shape[2],1)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Activation,Dense,Dropout,Flatten,Conv2D,MaxPooling2D,Flatten, LSTM\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "#from keras import backend as K\n",
    "#K.common.set_image_data_format('channels_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"./B.jpg\">\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<img src=\"./B.jpg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Convolutional layer-1: input size=128x12, filter size=13x6, stride=1x3\n",
    "model.add(Conv2D(filters=1,\n",
    "                 kernel_size=(13,6),\n",
    "                 strides=(1,3),\n",
    "                 input_shape=(128,12,1),\n",
    "                 data_format=\"channels_last\"))\n",
    "# (bs,128,12,1) -> (bs,116,3,1)\n",
    "\n",
    "#clipped-Relu\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "#BatchNormalization\n",
    "model.add(BatchNormalization(momentum=0.8))\n",
    "\n",
    "#Max_pooling layer-1: pool size=2x1, stride=2x1\n",
    "model.add(MaxPooling2D(pool_size=(2,1),\n",
    "                       strides=(2,1)))\n",
    "# (bs,116,3,1) -> (bs,58,3,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convolutional layer-2\n",
    "model.add(Conv2D(filters=1,\n",
    "                 kernel_size=(13,3),\n",
    "                 strides=(1,1)))\n",
    "# (bs,58,3,1) -> (bs,46,1,1)\n",
    "\n",
    "#clipped-Relu\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "#BatchNormalization\n",
    "model.add(BatchNormalization(momentum=0.8))\n",
    "\n",
    "#Max_pooling layer-2: pool size=2x1, stride=2x1\n",
    "model.add(MaxPooling2D(pool_size=(2,1),\n",
    "                       strides=(2,1)))\n",
    "# (bs,46,1,1) -> (bs,23,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convolutional layer-3\n",
    "model.add(Conv2D(filters=1,\n",
    "                 kernel_size=(12,1),\n",
    "                 strides=(1,1)))\n",
    "# (bs,23,1,1) -> (bs,12,1,1)\n",
    "\n",
    "#clipped-Relu\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "#BatchNormalization\n",
    "model.add(BatchNormalization(momentum=0.8))\n",
    "\n",
    "#Max_pooling layer-3: pool size=2x1, stride=2x1\n",
    "model.add(MaxPooling2D(pool_size=(2,1),\n",
    "                       strides=(2,1)))\n",
    "# (bs,12,1,1) -> (bs,6,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropout layer: 50%\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#Flatten\n",
    "model.add(Flatten())\n",
    "\n",
    "#Fully-connected layer: softmax\n",
    "model.add(Dense(6, activation='softmax', name=\"Dense1\"))\n",
    "\n",
    "# Dense1_output = model.get_layer(name=\"Dense1\").output\n",
    "# print(Dense1_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(lr=0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(result.shape)\n",
    "# train_history = model.fit(X_train, y_train, batch_size=128, epochs=100)\n",
    "# score = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(result)\n",
    "# print(X_train)\n",
    "train_history = model.fit(X_train, y_train, batch_size=16, epochs=100)\n",
    "score = model.evaluate(X_test, y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "7352/7352 [==============================] - 21s 3ms/step - loss: 1.3402 - accuracy: 0.4393 - val_loss: 1.2239 - val_accuracy: 0.4191\n",
      "Epoch 2/30\n",
      "7352/7352 [==============================] - 21s 3ms/step - loss: 1.0272 - accuracy: 0.5483 - val_loss: 1.0420 - val_accuracy: 0.6077\n",
      "Epoch 3/30\n",
      "7352/7352 [==============================] - 21s 3ms/step - loss: 0.8462 - accuracy: 0.6570 - val_loss: 0.9513 - val_accuracy: 0.6216\n",
      "Epoch 4/30\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.7414 - accuracy: 0.7258 - val_loss: 0.6455 - val_accuracy: 0.7642\n",
      "Epoch 5/30\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.5947 - accuracy: 0.7650 - val_loss: 0.6059 - val_accuracy: 0.7553\n",
      "Epoch 6/30\n",
      "7352/7352 [==============================] - 23s 3ms/step - loss: 0.4933 - accuracy: 0.8258 - val_loss: 0.5503 - val_accuracy: 0.8012\n",
      "Epoch 7/30\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.4076 - accuracy: 0.8770 - val_loss: 0.6280 - val_accuracy: 0.8059\n",
      "Epoch 8/30\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.3937 - accuracy: 0.8878 - val_loss: 0.5477 - val_accuracy: 0.8422\n",
      "Epoch 9/30\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.3288 - accuracy: 0.9037 - val_loss: 0.5031 - val_accuracy: 0.8473\n",
      "Epoch 10/30\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.2947 - accuracy: 0.9172 - val_loss: 0.4254 - val_accuracy: 0.8660\n",
      "Epoch 11/30\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.2602 - accuracy: 0.9271 - val_loss: 0.3526 - val_accuracy: 0.9006\n",
      "Epoch 12/30\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.2596 - accuracy: 0.9249 - val_loss: 0.4845 - val_accuracy: 0.8612\n",
      "Epoch 13/30\n",
      "7352/7352 [==============================] - 23s 3ms/step - loss: 0.2428 - accuracy: 0.9275 - val_loss: 0.3806 - val_accuracy: 0.9036\n",
      "Epoch 14/30\n",
      "7352/7352 [==============================] - 23s 3ms/step - loss: 0.2588 - accuracy: 0.9232 - val_loss: 0.6889 - val_accuracy: 0.8052\n",
      "Epoch 15/30\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.3795 - accuracy: 0.8912 - val_loss: 0.3382 - val_accuracy: 0.9046\n",
      "Epoch 16/30\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.2369 - accuracy: 0.9249 - val_loss: 0.3873 - val_accuracy: 0.8941\n",
      "Epoch 17/30\n",
      "7352/7352 [==============================] - 21s 3ms/step - loss: 0.2119 - accuracy: 0.9377 - val_loss: 0.4810 - val_accuracy: 0.8907\n",
      "Epoch 18/30\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.2091 - accuracy: 0.9373 - val_loss: 0.3624 - val_accuracy: 0.8982\n",
      "Epoch 19/30\n",
      "7352/7352 [==============================] - 21s 3ms/step - loss: 0.1809 - accuracy: 0.9429 - val_loss: 0.3895 - val_accuracy: 0.9070\n",
      "Epoch 20/30\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.1821 - accuracy: 0.9436 - val_loss: 0.3691 - val_accuracy: 0.9050\n",
      "Epoch 21/30\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.1716 - accuracy: 0.9440 - val_loss: 0.4128 - val_accuracy: 0.8982\n",
      "Epoch 22/30\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.1743 - accuracy: 0.9452 - val_loss: 0.5042 - val_accuracy: 0.8897\n",
      "Epoch 23/30\n",
      "7352/7352 [==============================] - 23s 3ms/step - loss: 0.1687 - accuracy: 0.9465 - val_loss: 0.3633 - val_accuracy: 0.9141\n",
      "Epoch 24/30\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.1625 - accuracy: 0.9502 - val_loss: 0.3680 - val_accuracy: 0.9108\n",
      "Epoch 25/30\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.1705 - accuracy: 0.9456 - val_loss: 0.3333 - val_accuracy: 0.9172\n",
      "Epoch 26/30\n",
      "7352/7352 [==============================] - 23s 3ms/step - loss: 0.1822 - accuracy: 0.9442 - val_loss: 0.5280 - val_accuracy: 0.8975\n",
      "Epoch 27/30\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.1782 - accuracy: 0.9461 - val_loss: 0.5153 - val_accuracy: 0.8907\n",
      "Epoch 28/30\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.1567 - accuracy: 0.9483 - val_loss: 0.3822 - val_accuracy: 0.9009\n",
      "Epoch 29/30\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.1793 - accuracy: 0.9445 - val_loss: 0.3206 - val_accuracy: 0.9080\n",
      "Epoch 30/30\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.1611 - accuracy: 0.9456 - val_loss: 0.3494 - val_accuracy: 0.9121\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x229254de308>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(LSTM(32, input_shape=(len(X_train[0]),len(X_train[0][0]))))\n",
    "model1.add(Dropout(0.5))\n",
    "model1.add(Dense(6, activation='sigmoid'))\n",
    "model1.compile(loss='categorical_crossentropy',optimizer='rmsprop',metrics=['accuracy'])\n",
    "model1.fit(X_train,\n",
    "          y_train,\n",
    "          batch_size=16,\n",
    "          validation_data=(X_test, y_test),\n",
    "          epochs=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
